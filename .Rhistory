return(theta_new)
}
#transition function
transition=function(theta,alpha,a,b)
{
n=length(theta)
u=runif(n)
u=as.numeric(u<=(1-alpha))
theta_new=theta*u+(a+(b-a)*runif(n))*(1-u)
return(theta_new)
}
#loss function
loss=function(theta,y)
{
return((theta-y)^2)
}
#exploss function
exploss = function(theta,y,mode=1,eta=1)
{
#\exp(-\eta loss(theta,y))
#mode = 1: first specify loss function then exp it
#mode = 0: directly calculate the "likelihood"
if(mode==1) {
el=exp(-eta*loss(theta,y));
}
else {el=dnorm(y,theta,1);}
return(el)
}
resampleMultinomial=function(w){
M=length(w)
Q=cumsum(w)
Q[M]=1
indx=rep(0,M)
i=1
while (i<=M) { sampl=runif(1)
j=1;
while(Q[j]<sampl){j=j+1}
indx[i]=j
i=i+1
}
return(indx)
}
#########################################################
isrejuvenate = 1
ismixing = 1
for (t in 1:(T-1))
{
#update weight
weight[t+1,]=weight[t,]*(exploss(tha_sample,Y[t],mode,eta))
Z[t+1]=sum(weight[t+1,])
weight[t+1,]=weight[t+1,]/Z[t+1]
Z[t+1]=Z[t]*Z[t+1]
#calculate ESS
ESS[t+1]=1/sum(weight[t+1,]^2)
resample_flag=0
if(ESS[t+1]<c*N)
{
#resample
resample_flag=1
ind=resampleMultinomial(weight[t+1,])    #Using multinomial distribution to resample.
tha_sample=tha_sample[ind]    #Decide which samples need to be resampled.
weight[t+1,]=rep(1,N)/N       #Obtain equal weights.
#rejuvenate/Move using MH kernal
if(isrejuvenate)
{
prop_mean=mean(tha_sample)
prop_sig=sd(tha_sample)
Coef=filteringdst_part1(t,alpha,Z)
Xcal=function(theta) {filteringdst_part2(theta,t,Y,mode,eta)}
# if(is.null(nrow(tha_sample)))
# {
#   targetdist=function(theta) {
#     return(t(Xcal(theta)%*%Coef)) }
#   }
# else {
targetdist=function(theta) {
return(t(Xcal(theta)%*%Coef))
}
# }
tha_sample=MH_move(tha_sample,targetdist,prop_mean,prop_sig)
}
}
#move according to mixing transition kernal
if(ismixing)
{
tha_sample=transition(tha_sample,alpha,a,b)
}
#   #plot
#
#
#
#
#
#   if(resample_flag){
#     hist(tha_sample,breaks = 50,freq=F, main=c('Predictive Distribution for t = ',t))
#     theta_hat[t+1]=mean(tha_sample)
#   }
#   else {
#     hist(tha_sample[ind],breaks = 50,freq = F, main=c('Predictive Distribution for t = ',t))
#     theta_hat[t+1]=mean(tha_sample[ind])
#     }
#   abline(v=theta_true[t],col='red',lwd=3)
#
#   resample[t+1]=resample_flag
#
# }
return(list(ESS=ESS,Z=Z,theta_hat=theta_hat,resample_flag=resample))
}
#
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
}
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
set.seed(0421)
a=-10;b=10
Data=datagenNoml(201,5,a,b)
Y=Data[[1]] #Data sequence
theta_true=Data[[2]] #True theta
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
Simulation$ESS
Simulation$theta_hat
T = 201;
k = 5;
a = -10;
b = 10;
d = b - a;
c=0.5
set.seed(0421)
datagenNoml = function(T,k,a,b,sig=1)
{
#generate the data sequence: from normal dist. with changing means
#also return the true parameter sequence
#k: number of abrupt changes
if(k==0)
{
theta_true=(a+(b-a)*runif(1))*rep(1,T)
Y=rnorm(T,theta_true,sig*rep(1,T))
}
change_point=floor(T/(k+1))*c(1:k)
change_point=c(1,change_point,T)
theta_list=a+(b-a)*runif(k+1)
theta_true=rep(0,T)
for(j in 1:(k+1))
{
theta_true[change_point[j]:change_point[j+1]]=theta_list[j]
}
#generate data
Y=rnorm(T,theta_true,sig*rep(1,T))
return(list(Y,theta_true))
}
#################################################
#Figure
set.seed(0421)
Data=datagenNoml(T,k,a,b)
Y=Data[[1]]
theta_true=Data[[2]]
plot(data.frame(x=1:201,y=Y),type='l',col='lightblue',ylim=c(a,b),ylab='Generate Data/True mean',xlab='time index')
par(new=TRUE)
plot(data.frame(x=1:201,y=theta_true),type='l',col='red',ylim=c(a,b),ylab='Generate Data/True mean',xlab='time index')
title(main="Normal Data Sequence")
par(new=TRUE)
plot(data.frame(x=1:201,y=Simulation$theta_hat),type='l',col='red',ylim=c(a,b),ylab='Generate Data/True mean',xlab='time index')
#particle filter: a SMC version
eta=0.1;                          #Learning rate: tune
mode=1; alpha=k/(T-1)
N=1000                             #Number of particles
tha_sample=a+d*runif(N)            #Initial samples
weight=matrix(0,T,N)               #Initial weights
weight[1,]=rep(1,N)/N
Z=rep(0,T)                         #normalizing constants
Z[1]=1                             #the prior is exactly known as a uniform
c=0.5
ESS=rep(0,T)
ESS[1]=N
uplim=0.5
#figure
hist(tha_sample,breaks=50,freq=F,ylim=c(0,uplim),
col='lightblue',main=c('Predictive Distribution for t = ',1),
xlim=c(a,b),xlab='sample')
abline(v=theta_true[1],ylim=0:uplim,lwd=3,col='red')
#########################################################
Sim=PFSMC(Y,eta,alpha,N=500,c,T,theta_true)
ESS=Sim[[1]]
Z=Sim[[2]]
theta_hat=Sim[[3]]
plot(ESS,type = 'l',main = 'ESS',xlab = 'Time Index t')
plot(log(Z),type='l',main='Normalizing Constants (log scale)',xlab='Time Index t')
PFSMC=function(Y,eta,alpha,N,c,T,theta_true,mode=1)
{
tha_sample=a+(b-a)*runif(N)        #Initial particles theta_1^i for i=1:N
weight=matrix(0,T,N)               #Initial weights W_1^i=1/N
weight[1,]=rep(1,N)/N
Z=rep(0,T)                         #normalizing constants
Z[1]=1                             #the prior is exactly known as a uniform
ESS=rep(0,T)                       #Effctive sample size.
ESS[1]=N
resample=numeric(T)
theta_hat=numeric(T)
#filteringdst_part1 function
filteringdst_part1=function(t,alpha,Z)
{
Coef=matrix(0,t,1)
Coef[1]=(1-alpha)^(t-1)
if(t>=2)
{
for(k in 2:t)
{
Coef[k]=alpha*(1-alpha)^(t-k)*Z[k]
}
}
return(Coef)
}
# filteringdst_part2 function
filteringdst_part2=function(theta,t,Y,mode=1,eta=1)
{
if(is.null(nrow(theta))) {theta=t(t(theta))}
X=matrix(0,length(theta),t)
if(mode==0){
X[,t]=exploss(theta,Y[t],mode,eta)
k=t-1
while(k>=1){
X[,k]=X[,k+1]*exploss(theta,Y[k],mode,eta)
k=k-1
}
}
else
{
X[,t]=loss(theta,Y[t])
k=t-1
while(k>=1){
X[,k]=X[,k+1]+loss(theta,Y[k])
k=k-1
}
X=exp(-eta*X)
}
return(X)
}
#MH_move function
MH_move=function(theta,targetdist,prop_mean,prop_sig)
{
# MH step to increase sample diversity with a normal proposal distribution
# proposal_mean and proposal_sig are better estimated from current samples
siz=length(theta)
theta_new=rnorm(siz,prop_mean,prop_sig)
a1=targetdist(theta_new)/targetdist(theta)
a2=dnorm(theta,prop_mean,prop_sig)/dnorm(theta_new,prop_mean,prop_sig)
a=a2*a1
accept=rep(0,length(a))
for (i in 1:length(a))
{
accept[i]=min(1,a[i])
}
u=runif(siz)
u=as.numeric(u<accept)
theta_new=theta_new*u+theta*(1-u)
return(theta_new)
}
#transition function
transition=function(theta,alpha,a,b)
{
n=length(theta)
u=runif(n)
u=as.numeric(u<=(1-alpha))
theta_new=theta*u+(a+(b-a)*runif(n))*(1-u)
return(theta_new)
}
#loss function
loss=function(theta,y)
{
return((theta-y)^2)
}
#exploss function
exploss = function(theta,y,mode=1,eta=1)
{
#\exp(-\eta loss(theta,y))
#mode = 1: first specify loss function then exp it
#mode = 0: directly calculate the "likelihood"
if(mode==1) {
el=exp(-eta*loss(theta,y));
}
else {el=dnorm(y,theta,1);}
return(el)
}
resampleMultinomial=function(w){
M=length(w)
Q=cumsum(w)
Q[M]=1
indx=rep(0,M)
i=1
while (i<=M) { sampl=runif(1)
j=1;
while(Q[j]<sampl){j=j+1}
indx[i]=j
i=i+1
}
return(indx)
}
#########################################################
isrejuvenate = 1
ismixing = 1
for (t in 1:(T-1))
{
#update weight
weight[t+1,]=weight[t,]*(exploss(tha_sample,Y[t],mode,eta))
Z[t+1]=sum(weight[t+1,])
weight[t+1,]=weight[t+1,]/Z[t+1]
Z[t+1]=Z[t]*Z[t+1]
#calculate ESS
ESS[t+1]=1/sum(weight[t+1,]^2)
resample_flag=0
if(ESS[t+1]<c*N)
{
#resample
resample_flag=1
ind=resampleMultinomial(weight[t+1,])    #Using multinomial distribution to resample.
tha_sample=tha_sample[ind]    #Decide which samples need to be resampled.
weight[t+1,]=rep(1,N)/N       #Obtain equal weights.
#rejuvenate/Move using MH kernal
if(isrejuvenate)
{
prop_mean=mean(tha_sample)
prop_sig=sd(tha_sample)
Coef=filteringdst_part1(t,alpha,Z)
Xcal=function(theta) {filteringdst_part2(theta,t,Y,mode,eta)}
# if(is.null(nrow(tha_sample)))
# {
#   targetdist=function(theta) {
#     return(t(Xcal(theta)%*%Coef)) }
#   }
# else {
targetdist=function(theta) {
return(t(Xcal(theta)%*%Coef))
}
# }
tha_sample=MH_move(tha_sample,targetdist,prop_mean,prop_sig)
}
}
#move according to mixing transition kernal
if(ismixing)
{
tha_sample=transition(tha_sample,alpha,a,b)
}
#plot
if(resample_flag){
hist(tha_sample,breaks = 50,freq=F, main=c('Predictive Distribution for t = ',t))
theta_hat[t+1]=mean(tha_sample)
}
else {
hist(tha_sample[ind],breaks = 50,freq = F, main=c('Predictive Distribution for t = ',t))
theta_hat[t+1]=mean(tha_sample[ind])
}
abline(v=theta_true[t],col='red',lwd=3)
resample[t+1]=resample_flag
}
return(list(ESS=ESS,Z=Z,theta_hat=theta_hat,resample_flag=resample))
}
Sim=PFSMC(Y,eta,alpha,N=500,c,T,theta_true)
ESS=Sim[[1]]
Z=Sim[[2]]
theta_hat=Sim[[3]]
plot(ESS,type = 'l',main = 'ESS',xlab = 'Time Index t')
plot(log(Z),type='l',main='Normalizing Constants (log scale)',xlab='Time Index t')
plot(ESS,type = 'l',main = 'ESS',xlab = 'Time Index t')
library(PFSMC)
set.seed(0421)
a=-10;b=10
Data=datagenNoml(201,5,a,b)
Y=Data[[1]] #Data sequence
theta_true=Data[[2]] #True theta
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
Simulation
library(PFSMC)
set.seed(0421)
a=-10;b=10 #Parameter space
Data=datagenNoml(201,5,a,b)
Y=Data[[1]] #Data sequence
theta_true=Data[[2]] #True theta
Simulation<-PFSMC(Y=Y,eta=0.1,alpha=0.025,N=1000,c=0.5,T=201,theta_true=theta_true)
plot(theta_true)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
loss=function(theta,y) {
return((theta-y)^2)
}
exploss = function(theta,y,mode=1,eta=1) {
#mode = 1: first specify loss function then exp it
#mode = 0: directly calculate the "likelihood"
if(mode==1) {
el=exp(-eta*loss(theta,y));
} else {
el=dnorm(y,theta,1);
}
return(el)
}
resampleMultinomial=function(weight) {
M=length(weight)
Q=cumsum(weight)
Q[M]=1
indx=rep(0,M) #store sample index
i=1
while (i<=M) {
sampl=runif(1)
j=1;
while(Q[j]<sampl) {
j=j+1
}
indx[i]=j
i=i+1
}
return(indx)
}
MH_move=function(theta,targetdist,prop_mean,prop_sig) {
siz=length(theta)
theta_new=rnorm(siz,prop_mean,prop_sig) #Generate samples from proposal distribution
a1=targetdist(theta_new)/targetdist(theta)
a2=dnorm(theta,prop_mean,prop_sig)/dnorm(theta_new,prop_mean,prop_sig)
a=a2*a1
#Accept the new candidate with probability min(1,a); otherwise just stay at the previous state.
accept=rep(0,length(a))
for (i in 1:length(a)) {
accept[i]=min(1,a[i]) #alpha = min(1,a)
}
u=runif(siz) #The probability of accepting the new candidate
u=as.numeric(u<accept)
theta_new=theta_new*u+theta*(1-u)
return(theta_new) #Return the Markov chain.
}
transition=function(theta,alpha) {
n=length(theta)
u=runif(n)
u=as.numeric(u<=(1-alpha))
theta_new=theta*u+(-10+20*runif(n))*(1-u)
return(theta_new)
}
tha_sample=-10+20*runif(1000) #Initial particles theta_1^i for i=1:N
weight=matrix(0,201,1000) #Store weights at each time
weight[1,]=rep(1,1000)/1000 #Initial weights W_1^i=1/N
Z=rep(0,201) #Normalizing constants denoted in step 5
Z[1]=1 #Sum of weights is equal to 1 with equal weights
ESS=rep(0,201) #Store effctive sample sizes
ESS[1]=1000 #Initial effective sample size N
resample=numeric(201) #Store resample flags
theta_hat=numeric(201) #Store predicted parameters
datagenNoml = function(T,k,a,b,sig=1) {
if(k==0) {
theta_true=(a+(b-a)*runif(1))*rep(1,T)
Y=rnorm(T,theta_true,sig*rep(1,T))
}
#determine the chage point randomly
change_point=floor(T/(k+1))*c(1:k)
change_point=c(1,change_point,T)
theta_list=a+(b-a)*runif(k+1)
theta_true=rep(0,T)
#Generate the true parameter
for(j in 1:(k+1)) {
theta_true[change_point[j]:change_point[j+1]]=theta_list[j]
}
#Generate data
Y=rnorm(T,theta_true,sig*rep(1,T))
return(list(Y,theta_true))
}
remove.packages("PFSMC")
remove.packages("PFtracking")
devtools::install_github("azure10h/PFSMC")
library(PFSMC)
document()
getwd()
seted(~/Desktop/test/PFSMC)
seted("~/Desktop/test/PFSMC"")
)
""
seted("~/Desktop/test/PFSMC")
setwd("~/Desktop/test/PFSMC")
document()
devtools::document()
View(library.dynam.unload)
View(library.dynam.unload)
View(library.dynam.unload)
require(PFSMC)
remove.packages("PFSMC")
devtools::install_github("azure10h/PFSMC",auth_token = "c22250b35d5babee1d5c0b6f78a4c940ac9af445")
library(PFSMC)
remove.packages("PFSMC")
devtools::install_github("azure10h/PFSMC",auth_token = "c22250b35d5babee1d5c0b6f78a4c940ac9af445")
ls()
remove(PFSMC)
ls()
remove.packages("PFSMC")
devtools::install_github("azure10h/PFSMC",auth_token = "c22250b35d5babee1d5c0b6f78a4c940ac9af445")
library(PFSMC)
help(PFSMC)
View(system.file)
PFSMC::system.file()
.libPaths(PFSMC)
library(PFSMC)
PFSMC::library.dynam.unload()
getwd()
build()
devtools::build()
install.packages("~/Desktop/PFSMC_0.1.0.tar.gz", repos = NULL, type = "source")
library(PFSMC)
#Install the package from Github
devtools::install_github("azure10h/PFSMC",
auth_token = "c22250b35d5babee1d5c0b6f78a4c940ac9af445")
library(PFSMC)
help(PFSMC)
help(datagenNoml)
help(resampleMultinomial)
require(PFSMC)
help(loss)
